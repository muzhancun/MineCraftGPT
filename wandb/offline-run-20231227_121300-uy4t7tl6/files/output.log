{'loss': 3.2524, 'learning_rate': 1.25e-05, 'epoch': 0.82}
{'eval_loss': 2.8136374950408936, 'eval_runtime': 7.491, 'eval_samples_per_second': 36.043, 'eval_steps_per_second': 9.078, 'epoch': 1.0}
{'loss': 2.8504, 'learning_rate': 2.5e-05, 'epoch': 1.65}
{'eval_loss': 2.6728479862213135, 'eval_runtime': 7.498, 'eval_samples_per_second': 36.01, 'eval_steps_per_second': 9.069, 'epoch': 2.0}
{'loss': 2.6949, 'learning_rate': 3.7500000000000003e-05, 'epoch': 2.47}
{'eval_loss': 2.5960376262664795, 'eval_runtime': 7.5133, 'eval_samples_per_second': 35.936, 'eval_steps_per_second': 9.051, 'epoch': 3.0}
{'loss': 2.5619, 'learning_rate': 5e-05, 'epoch': 3.29}
{'eval_loss': 2.5421431064605713, 'eval_runtime': 7.4979, 'eval_samples_per_second': 36.01, 'eval_steps_per_second': 9.069, 'epoch': 4.0}
{'loss': 2.4478, 'learning_rate': 4.7534516765285995e-05, 'epoch': 4.12}
{'loss': 2.3286, 'learning_rate': 4.5069033530571994e-05, 'epoch': 4.94}
{'eval_loss': 2.5167641639709473, 'eval_runtime': 7.4834, 'eval_samples_per_second': 36.08, 'eval_steps_per_second': 9.087, 'epoch': 5.0}
{'loss': 2.2334, 'learning_rate': 4.260355029585799e-05, 'epoch': 5.77}
{'eval_loss': 2.5038654804229736, 'eval_runtime': 7.5141, 'eval_samples_per_second': 35.933, 'eval_steps_per_second': 9.05, 'epoch': 6.0}
{'loss': 2.1783, 'learning_rate': 4.0138067061143986e-05, 'epoch': 6.59}
{'eval_loss': 2.4978322982788086, 'eval_runtime': 7.4871, 'eval_samples_per_second': 36.062, 'eval_steps_per_second': 9.082, 'epoch': 7.0}
{'loss': 2.0715, 'learning_rate': 3.767258382642998e-05, 'epoch': 7.41}
{'eval_loss': 2.496689558029175, 'eval_runtime': 7.519, 'eval_samples_per_second': 35.909, 'eval_steps_per_second': 9.044, 'epoch': 8.0}
{'loss': 2.0295, 'learning_rate': 3.520710059171598e-05, 'epoch': 8.24}
{'eval_loss': 2.501845598220825, 'eval_runtime': 7.4939, 'eval_samples_per_second': 36.029, 'eval_steps_per_second': 9.074, 'epoch': 9.0}
{'loss': 1.98, 'learning_rate': 3.2741617357001976e-05, 'epoch': 9.06}
{'loss': 1.8948, 'learning_rate': 3.027613412228797e-05, 'epoch': 9.88}
{'eval_loss': 2.517167091369629, 'eval_runtime': 7.4763, 'eval_samples_per_second': 36.114, 'eval_steps_per_second': 9.095, 'epoch': 10.0}
{'loss': 1.8777, 'learning_rate': 2.7810650887573965e-05, 'epoch': 10.71}
{'eval_loss': 2.5215299129486084, 'eval_runtime': 7.4891, 'eval_samples_per_second': 36.052, 'eval_steps_per_second': 9.08, 'epoch': 11.0}
{'loss': 1.8162, 'learning_rate': 2.5345167652859964e-05, 'epoch': 11.53}
{'eval_loss': 2.5443952083587646, 'eval_runtime': 7.4928, 'eval_samples_per_second': 36.035, 'eval_steps_per_second': 9.075, 'epoch': 12.0}
{'loss': 1.7917, 'learning_rate': 2.287968441814596e-05, 'epoch': 12.36}
{'eval_loss': 2.5474112033843994, 'eval_runtime': 7.493, 'eval_samples_per_second': 36.033, 'eval_steps_per_second': 9.075, 'epoch': 13.0}
{'loss': 1.7487, 'learning_rate': 2.0414201183431952e-05, 'epoch': 13.18}
{'eval_loss': 2.5711867809295654, 'eval_runtime': 7.4878, 'eval_samples_per_second': 36.059, 'eval_steps_per_second': 9.081, 'epoch': 14.0}
{'loss': 1.7234, 'learning_rate': 1.794871794871795e-05, 'epoch': 14.0}
{'loss': 1.6953, 'learning_rate': 1.5483234714003947e-05, 'epoch': 14.83}
{'eval_loss': 2.583717107772827, 'eval_runtime': 7.4759, 'eval_samples_per_second': 36.116, 'eval_steps_per_second': 9.096, 'epoch': 15.0}
{'loss': 1.6714, 'learning_rate': 1.3017751479289941e-05, 'epoch': 15.65}
{'eval_loss': 2.596987247467041, 'eval_runtime': 7.4931, 'eval_samples_per_second': 36.033, 'eval_steps_per_second': 9.075, 'epoch': 16.0}
{'loss': 1.6356, 'learning_rate': 1.0552268244575937e-05, 'epoch': 16.47}
{'eval_loss': 2.6119558811187744, 'eval_runtime': 7.4846, 'eval_samples_per_second': 36.074, 'eval_steps_per_second': 9.085, 'epoch': 17.0}
{'loss': 1.6055, 'learning_rate': 8.086785009861933e-06, 'epoch': 17.3}
{'eval_loss': 2.611396312713623, 'eval_runtime': 7.4967, 'eval_samples_per_second': 36.016, 'eval_steps_per_second': 9.071, 'epoch': 18.0}
{'loss': 1.619, 'learning_rate': 5.621301775147929e-06, 'epoch': 18.12}
{'loss': 1.6006, 'learning_rate': 3.1558185404339255e-06, 'epoch': 18.95}
{'eval_loss': 2.6213974952697754, 'eval_runtime': 7.4914, 'eval_samples_per_second': 36.041, 'eval_steps_per_second': 9.077, 'epoch': 19.0}
{'loss': 1.587, 'learning_rate': 6.903353057199211e-07, 'epoch': 19.77}
{'eval_loss': 2.625351667404175, 'eval_runtime': 7.4921, 'eval_samples_per_second': 36.038, 'eval_steps_per_second': 9.076, 'epoch': 20.0}
{'train_runtime': 4179.022, 'train_samples_per_second': 11.61, 'train_steps_per_second': 2.905, 'train_loss': 2.0323303737986027, 'epoch': 20.0}
  0%|          | 0/12140 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
100%|██████████| 12140/12140 [1:09:32<00:00,  2.91it/s]