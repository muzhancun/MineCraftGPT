{'loss': 3.2525, 'learning_rate': 1.25e-05, 'epoch': 0.82}
{'eval_loss': 2.8584961891174316, 'eval_runtime': 7.5522, 'eval_samples_per_second': 35.751, 'eval_steps_per_second': 9.004, 'epoch': 1.0}
{'loss': 2.9379, 'learning_rate': 2.5e-05, 'epoch': 1.65}
{'eval_loss': 2.6900951862335205, 'eval_runtime': 7.5975, 'eval_samples_per_second': 35.538, 'eval_steps_per_second': 8.95, 'epoch': 2.0}
{'loss': 2.7834, 'learning_rate': 3.7500000000000003e-05, 'epoch': 2.47}
{'eval_loss': 2.5866706371307373, 'eval_runtime': 7.5506, 'eval_samples_per_second': 35.759, 'eval_steps_per_second': 9.006, 'epoch': 3.0}
{'loss': 2.656, 'learning_rate': 5e-05, 'epoch': 3.29}
{'eval_loss': 2.511559247970581, 'eval_runtime': 7.5611, 'eval_samples_per_second': 35.709, 'eval_steps_per_second': 8.993, 'epoch': 4.0}
{'loss': 2.5472, 'learning_rate': 4.7534516765285995e-05, 'epoch': 4.12}
{'loss': 2.4176, 'learning_rate': 4.5069033530571994e-05, 'epoch': 4.94}
{'eval_loss': 2.4629878997802734, 'eval_runtime': 7.5654, 'eval_samples_per_second': 35.689, 'eval_steps_per_second': 8.988, 'epoch': 5.0}
{'loss': 2.2977, 'learning_rate': 4.260355029585799e-05, 'epoch': 5.77}
{'eval_loss': 2.4376256465911865, 'eval_runtime': 7.5826, 'eval_samples_per_second': 35.608, 'eval_steps_per_second': 8.968, 'epoch': 6.0}
{'loss': 2.2043, 'learning_rate': 4.0138067061143986e-05, 'epoch': 6.59}
{'eval_loss': 2.4330077171325684, 'eval_runtime': 7.594, 'eval_samples_per_second': 35.554, 'eval_steps_per_second': 8.954, 'epoch': 7.0}
{'loss': 2.1188, 'learning_rate': 3.767258382642998e-05, 'epoch': 7.41}
{'eval_loss': 2.438084125518799, 'eval_runtime': 7.569, 'eval_samples_per_second': 35.672, 'eval_steps_per_second': 8.984, 'epoch': 8.0}
{'loss': 2.0793, 'learning_rate': 3.520710059171598e-05, 'epoch': 8.24}
{'eval_loss': 2.43503999710083, 'eval_runtime': 7.5661, 'eval_samples_per_second': 35.685, 'eval_steps_per_second': 8.987, 'epoch': 9.0}
{'loss': 1.9882, 'learning_rate': 3.2741617357001976e-05, 'epoch': 9.06}
{'loss': 1.9435, 'learning_rate': 3.027613412228797e-05, 'epoch': 9.88}
{'eval_loss': 2.4488892555236816, 'eval_runtime': 7.5791, 'eval_samples_per_second': 35.624, 'eval_steps_per_second': 8.972, 'epoch': 10.0}
{'loss': 1.8763, 'learning_rate': 2.7810650887573965e-05, 'epoch': 10.71}
{'eval_loss': 2.4633517265319824, 'eval_runtime': 7.5868, 'eval_samples_per_second': 35.588, 'eval_steps_per_second': 8.963, 'epoch': 11.0}
{'loss': 1.8254, 'learning_rate': 2.5345167652859964e-05, 'epoch': 11.53}
{'eval_loss': 2.485866069793701, 'eval_runtime': 7.58, 'eval_samples_per_second': 35.62, 'eval_steps_per_second': 8.971, 'epoch': 12.0}
{'loss': 1.8203, 'learning_rate': 2.287968441814596e-05, 'epoch': 12.36}
{'eval_loss': 2.4869275093078613, 'eval_runtime': 7.5792, 'eval_samples_per_second': 35.624, 'eval_steps_per_second': 8.972, 'epoch': 13.0}
{'loss': 1.7485, 'learning_rate': 2.0414201183431952e-05, 'epoch': 13.18}
{'eval_loss': 2.495624303817749, 'eval_runtime': 7.5749, 'eval_samples_per_second': 35.644, 'eval_steps_per_second': 8.977, 'epoch': 14.0}
{'loss': 1.7333, 'learning_rate': 1.794871794871795e-05, 'epoch': 14.0}
{'loss': 1.6919, 'learning_rate': 1.5483234714003947e-05, 'epoch': 14.83}
{'eval_loss': 2.503753662109375, 'eval_runtime': 7.5746, 'eval_samples_per_second': 35.645, 'eval_steps_per_second': 8.977, 'epoch': 15.0}
{'loss': 1.6604, 'learning_rate': 1.3017751479289941e-05, 'epoch': 15.65}
{'eval_loss': 2.5170440673828125, 'eval_runtime': 7.5618, 'eval_samples_per_second': 35.706, 'eval_steps_per_second': 8.993, 'epoch': 16.0}
{'loss': 1.649, 'learning_rate': 1.0552268244575937e-05, 'epoch': 16.47}
{'eval_loss': 2.5273966789245605, 'eval_runtime': 7.568, 'eval_samples_per_second': 35.677, 'eval_steps_per_second': 8.985, 'epoch': 17.0}
{'loss': 1.6373, 'learning_rate': 8.086785009861933e-06, 'epoch': 17.3}
{'eval_loss': 2.5382001399993896, 'eval_runtime': 7.567, 'eval_samples_per_second': 35.681, 'eval_steps_per_second': 8.986, 'epoch': 18.0}
{'loss': 1.6184, 'learning_rate': 5.621301775147929e-06, 'epoch': 18.12}
{'loss': 1.6094, 'learning_rate': 3.1558185404339255e-06, 'epoch': 18.95}
{'eval_loss': 2.5459744930267334, 'eval_runtime': 7.5832, 'eval_samples_per_second': 35.605, 'eval_steps_per_second': 8.967, 'epoch': 19.0}
{'loss': 1.5957, 'learning_rate': 6.903353057199211e-07, 'epoch': 19.77}
{'eval_loss': 2.5501997470855713, 'eval_runtime': 7.5774, 'eval_samples_per_second': 35.632, 'eval_steps_per_second': 8.974, 'epoch': 20.0}
{'train_runtime': 4208.2906, 'train_samples_per_second': 11.53, 'train_steps_per_second': 2.885, 'train_loss': 2.0654151187500807, 'epoch': 20.0}
  0%|          | 0/12140 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
100%|██████████| 12140/12140 [1:10:01<00:00,  2.89it/s]